Agriculture remains one of the most vital sectors for food security and economic growth globally, particularly in developing nations. Millet, a cereal grain known for its resilience to drought and adverse climatic conditions, is a staple crop in many parts of Asia and Africa. Its importance is underscored by the increasing demand for nutritious food in regions prone to food insecurity. Despite their robustness, millet crops are extremely vulnerable to a variety of illnesses, including as bacterial, viral, and fungal infections, which can cause significant production losses if they are not identified and treated promptly. Early and accurate disease detection is crucial to minimizing these losses, ensuring food supply stability, and supporting farmers' livelihoods.
Traditionally, the detection of plant diseases relies heavily on manual inspections by agricultural experts or farmers. These methods, though effective in some contexts, are time-consuming, require specialized knowledge, and are often limited by the subjective nature of visual assessments. Furthermore, delayed response may worsen the disease's spread and further harm crops if early access to disease-related information is not obtained. There is a growing need for automated, scalable solutions that can help with early disease identification and intervention due to the rising worldwide demand for agricultural output and the need to address the problems posed by climate change. 
The Latest evolution in AI, mostly DL, have the potential to revolutionize a number of industries, including agriculture. One type of deep learning technique that has shown great promise in picture analysis and classification is Convolutional Neural Networks (CNNs). CNNs are perfect for applications like plant disease detection because they excel at tasks like image recognition, pattern identification, and classification. In recent years, transfer learning—using pre-trained models on large datasets and fine-tuning them for particular tasks—has gained popularity since it significantly reduces the need for massive quantities of labeled data while still improving the model's performance.
This work introduces the Millet Disease Detection System, which uses deep learning-based techniques to overcome the difficulties associated with early disease detection in millet crops. To determine if millet leaf photos are healthy or diseased, the system uses a number of pre-trained models, which are MobileNetV2 and ResNet50. Even with a very small dataset, the models can apply their prior knowledge gained from large-scale picture datasets, like ImageNet, to the millet disease detection problem thanks to the application of transfer learning which is been used.
A scathing aspect of this analysis is the implementation of extensive data augmentation techniques. These techniques, including transformations such as rotation, zooming, and flipping, enhance the diversity of the training data. This reduces the risk of overfitting and improves the model's ability to generalize. Training on augmented data enables models to better manage real-world variability, such as differences in lighting, angles, or backgrounds in leaf images.
The models are assessed using standard metrics such as accuracy, precision, recall, and F1-score, emphasizing their effectiveness in distinguishing between healthy and diseased leaves. Their performance is compared to identify the most effective approach for detecting diseases in millet crops. By incorporating these deep learning models into a practical system, this research seeks to equip farmers with an automated disease detection tool, offering faster and more accurate diagnoses than traditional methods.
The efficacy of disease control in millet farming might be greatly increased by the suggested approach. Automated techniques for early detection can result in speedier treatments, limiting crop losses and the spread of diseases. Furthermore, the system may be used in a variety of agricultural contexts, providing scalability and flexibility to accommodate crop varieties other than millet. The wider ramifications of this study underscore the increasing significance of artificial intelligence (AI) and DL in precision agriculture, where intelligent systems may promote sustainable agricultural methods and improve global food security.
With population increase, resource constraint, and climate change putting further strain on the agriculture sector, creative solutions like the Millet Disease detection with population increase, resource constraint, and climate change putting further strain on the agriculture sector, creative solutions like the Millet Disease Detection System can play a pivotal role in ensuring that crop production remains efficient, sustainable, and resilient. Future work in this domain will focus on enhancing the dataset with more diverse crop images, exploring real-time deployment strategies, and optimizing model performance for faster and more reliable predictions in operational environments.

I.	PROPOSED METHODOLOGY
The Plant UML graphic that follows gives a visual summary of the complete process and summarizes the general flow of the suggested technique. As illustrated in Figure 1, this study proposes DL-based picture classification method that uses CNNs to automate the classification of crop illnesses. Data preparation, model construction, model training, evaluation, and other crucial phases comprise the methodology's framework, and deployment through a Flask application for real-time inference. The proposed approach leverages pre-trained models, namely MobileNetV2 and ResNet50, to optimize the performance of crop disease classification.

a.	Data Collection and Preprocessing
The dataset consists of 14 classes of millet diseases, categorized as follows: 
Finger Millet (Ragi): Downy, Mottle, Smut, Wilt, Healthy
Pearl Millet: Healthy, Rust, Downy Mildew
Sorghum (Jowar): Blast, Ergot, Smut, Rust, Healthy

These are used for training the models consist of images. To improve the model's resilience and avoid overfitting, data augmentation methods including rotation, zooming, flipping, and shifting are applied to the training dataset. To satisfy the input specifications of the pre-trained models, the photos are scaled to a uniform shape (224x224 pixels). To assess the model's performance, the dataset is divided into subsets for training (80%) and validation (20%).
To improve the decision-making, the dataset was restructured into two categories:
Treatable: Diseases that can be managed with proper intervention.
Non-Treatable: Severe diseases that significantly impact yield.
b.	Model Development
To develop the model, we leverage transfer learning by using pre-trained deep learning architectures—MobileNetV2, and ResNet50—as the foundational models. These architectures, originally trained on the large-scale ImageNet dataset for image classification, are fine-tuned to adapt specifically to the crop classification task. The base models are used as feature extractors, with the final layers replaced by custom fully connected layers tailored to the binary or multi-class classification problem.
Model	Accuracy (%)	Training Time	Performance Notes
MobieNetV2	94	Fast	Best performance, lightweight
ResNet50	37	Very Slow	High complexity, poor accuracy

Only the recently added classification layers are trained during the initial training phase, as the basic model layers are frozen to prevent overfitting and lower computational costs. The models are trained using the Adam optimizer with a learning rate of 1e-4 and a sparse categorical cross-entropy loss function. MobileNetV2 was chosen for deployment due to its superior accuracy and efficiency.
c.	Model Training and Evaluation
To make sure the models generalizes effectively to unknown data, the training procedure includes tracking the accuracy of both training and validation as well as the loss. To effectively classify millet diseases and determine their treatability, we initially trained deep learning models on a 14-class millet disease dataset. The dataset consisted of images representing various millet diseases, including Finger Millet Downy, Pearl Millet Rust, Sorghum blast, and Healthy Samples. The first phase of model training involved using MobileNetV2 and ResNet50 to classify these 14 disease types. However, MobileNetV2 outperformed with 94% accuracy, making it the preferred model for further processing.
After obtaining a robust disease classification model, we transformed the dataset to create a binary classification system distinguishing between treatable and non-treatable diseases. This was done by leveraging MobileNetV2’s feature extraction capabilities to identify patterns in diseases that responded well to treatment. Images were re-labelled based on expert knowledge and model outputs, categorizing diseases as either treatable (manageable with interventions) or non-treatable (severe damage, no effective cure). A learning rate scheduler is also used to dynamically modify the learning rate in response to the model's training progress. A distinct validation dataset is used to assess each model, and important performance measures like classification report, confusion matrix, accuracy, and loss are calculated. The top-performing model for the crop classification task is then determined by comparing the models.
The figure is the plot of confusion matrix so that the accuracy of the model can be judged. From the figure the outcome which comes into mind is that the model was trained well because most of the elements are present diagonally.
 

d.	Model Deployment via Flask
The final trained model is integrated into a Flask web application for real-time crop disease classification. The Flask application allows farmers to upload images and receive real-time disease detection results, including the disease name, its treatability status, and recommendation solutions.
Additionally, the model is integrated into an AI-driven chatbot to assist farmers with disease management queries. Upon receiving an image, the system predicts the disease and classifies it as treatable or non-treatable. The chatbot then provides automated responses, suggesting appropriate solutions or alternative strategies based on real-time predictions. The integration of this treatability classification system ensures that farmers receive precise, actionable insights, thereby enhancing disease management in millet farming.

II.	  RESULT
Here, four distinct deep learning models—ResNet50, and MobileNetV2—are used to assess the effectiveness of the suggested Millet Disease Detection System. Validation accuracy, validation loss, and classification metrics including precision, recall, and F1-score were used to assess these models for the "Treatability" and "Non-Treatability" of the diseases.
A. Evaluation Metrics
The performance of the Millet Disease Detection System was evaluated using various deep learning models, focusing on both disease classification and treatability prediction. The evaluation process included key metrics such as accuracy, precision, recall, F1-score, and confusion matrix analysis. The training process incorporated early stopping to prevent overfitting and a learning rate scheduler to dynamically adjust the learning rate during training. Each model was tested on a separate validation dataset, and performance metrics were recorded to determine the most effective approach for millet disease classification and treatability assessment. 
B. Performance of Individual Models
1. ResNet50
The ResNet50 model underperformed significantly, achieving a validation accuracy of only 37% and taking over 5.5 hours for training. Despite its deep architecture, it struggled to extract relevant features from the millet dataset, likely due to insufficient parameter tuning as the dataset was divided into 14 classes which were treated as labels by the model rather than labelling individual class images. Given its poor performance, ResNet50 was not selected for final deployment.
2. MobileNetV2 (Disease Classification)
The MobileNetV2 model achieved an impressive validation accuracy of 94%, significantly outperforming ResNet50. Due to its lightweight architecture and efficient feature extraction, MobileNetV2 demonstrated high recall and precision in classifying millet diseases into 14 distinct classes. This model was chosen as the primary classification model for millet disease detection.
3. MobileNetV2 (Treatability Classification)
After transforming the dataset into treatable and non-treatable categories, we trained a binary classifier using MobileNetV2. The final model achieved a validation accuracy of 96.2%, indicating high reliability in predicting disease treatability.
Table 2 CLASSIFICATION REPORT FOR MOBILENETV2 for Treatability Prediction
Metrics	MobileNetV2 (Treatability Model)
Accuracy	96.2%
Precision	95.8%
Recall	96.5%
F1-score	96.1%
  
C. Comparative Performance Of All Models
 Table 3 presents a comparative analysis of the models used in the study. MobileNetV2 demonstrated superior performance, achieving the highest accuracy while maintaining computational efficiency. In contrast, resNet50 failed to generalize well, making it unsuitable for deployment.
Table 2 Comparative Performance of Different Models.
Model	Validation Accuracy (%)	Validation Loss
ResNet50	37.0%	5.5 hours (training time)
MobileNetV2 (14-class classificiation)	94.0%	0.47
MobileNetV2 (Treatability classification)	96.2%	0.32
The classification report for MobileNetV2 showed strong precision and recall for detecting both diseased and healthy millet plants. The model successfully distinguished between treatable and non-treatable diseases, ensuring that farmers receive appropriate recommendations based on real-time analysis..   Figure 5 Accuracy graph for Validation for ResNet50, and MobileNetV2 models
